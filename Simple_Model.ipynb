{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.framework import dtypes\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.python.framework import graph_util\n",
    "from os.path import isfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_directory = 'data/'\n",
    "image_directory = 'data/Pre_train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='all', dtype=<class 'numpy.float64'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.fit(np.arange(3).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.transform([[0], [1], [2]]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = 32\n",
    "batch_size = 256\n",
    "num_channels = 3\n",
    "training_iters = 1001\n",
    "display = 10\n",
    "drop = 0.75\n",
    "save_step = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_label_files(csv_file):\n",
    "    file = open(data_directory+csv_file, 'r')\n",
    "    filepaths = []\n",
    "    labels = []\n",
    "    for i in file:\n",
    "        filename, label = i.split(',')\n",
    "        filepaths.append(image_directory+filename)\n",
    "        labels.append(int(label))\n",
    "    return filepaths, labels    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path, train_labels = read_label_files('train_set.csv')\n",
    "vali_path, vali_labels = read_label_files('vali_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vali_batch_size = len(vali_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path_tensor = ops.convert_to_tensor(train_path, dtype=dtypes.string)\n",
    "vali_path_tensor = ops.convert_to_tensor(vali_path, dtype=dtypes.string)\n",
    "train_labels_tensor = ops.convert_to_tensor(train_labels, dtype=dtypes.int32)\n",
    "vali_labels_tensor = ops.convert_to_tensor(vali_labels, dtype=dtypes.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_input_queue = tf.train.slice_input_producer(\n",
    "                                    [train_path_tensor, train_labels_tensor],\n",
    "                                    shuffle=True)\n",
    "vali_input_queue = tf.train.slice_input_producer(\n",
    "                                    [vali_path_tensor, vali_labels_tensor],\n",
    "                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_content = tf.read_file(train_input_queue[0])\n",
    "train_image = tf.image.decode_jpeg(file_content, channels=num_channels)\n",
    "train_image /= 255\n",
    "train_label = train_input_queue[1]\n",
    "\n",
    "file_content = tf.read_file(vali_input_queue[0])\n",
    "vali_image = tf.image.decode_jpeg(file_content, channels=num_channels)\n",
    "vali_image /= 255\n",
    "vali_label = vali_input_queue[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_image.set_shape([size, size, num_channels])\n",
    "vali_image.set_shape([size, size, num_channels])\n",
    "\n",
    "train_batch = tf.train.batch(\n",
    "                            [train_image, train_label],\n",
    "                            batch_size= batch_size\n",
    "                            )\n",
    "vali_batch = tf.train.batch(\n",
    "                            [vali_image, vali_label],\n",
    "                            batch_size = vali_batch_size\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def freeze_graph(model_folder):\n",
    "\n",
    "    checkpoint = tf.train.get_checkpoint_state(model_folder)\n",
    "    input_checkpoint = checkpoint.model_checkpoint_path\n",
    "    model_name = 'model_v3'\n",
    "    absolute_model_folder = \"/\".join(input_checkpoint.split('/')[:-1])\n",
    "    output_graph = absolute_model_folder + \"/\" + model_name + \".pb\"\n",
    "\n",
    "    output_node_names = \"final_output\"\n",
    "\n",
    "    clear_devices = True\n",
    "\n",
    "    saver = tf.train.import_meta_graph(input_checkpoint + '.meta', clear_devices=clear_devices)\n",
    "\n",
    "    graph = tf.get_default_graph()\n",
    "    input_graph_def = graph.as_graph_def()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, input_checkpoint)\n",
    "\n",
    "        output_graph_def = graph_util.convert_variables_to_constants(\n",
    "            sess,\n",
    "            input_graph_def,\n",
    "            output_node_names.split(\",\")\n",
    "        )\n",
    "\n",
    "        with tf.gfile.GFile(output_graph, \"wb\") as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "        print(\"%d ops in the final graph.\" % len(output_graph_def.node))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     coord = tf.train.Coordinator()\n",
    "#     threads = tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "#     for i in range(1):\n",
    "#         test = sess.run(train_batch)\n",
    "#     coord.request_stop()\n",
    "#     coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# image, label = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(image.shape)\n",
    "# print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape = [None, size, size, 3])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32, shape=[None, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "        'wc1':tf.Variable(tf.random_normal([5, 5, 3, 32])),\n",
    "        'wc2':tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "        'wc3':tf.Variable(tf.random_normal([3, 3, 64, 64])),\n",
    "        'wf1':tf.Variable(tf.random_normal([8 * 8 * 64, 1024])),\n",
    "        'wf2':tf.Variable(tf.random_normal([1024, 100])),\n",
    "        'out':tf.Variable(tf.random_normal([100, 3]))\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bias = {\n",
    "        'bc1' : tf.Variable(tf.random_normal([32])),\n",
    "        'bc2' : tf.Variable(tf.random_normal([64])),\n",
    "        'bc3' : tf.Variable(tf.random_normal([64])),\n",
    "        'bf1' : tf.Variable(tf.random_normal([1024])),\n",
    "        'bf2' : tf.Variable(tf.random_normal([100])),\n",
    "        'out':tf.Variable(tf.random_normal([3]))\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_net(input_image):\n",
    "        conv1 = tf.nn.conv2d(input_image, weights['wc1'], [1, 1, 1, 1], padding='SAME')\n",
    "        conv1 = tf.add(conv1, bias['bc1'])\n",
    "        conv1 = tf.nn.relu(conv1)\n",
    "        max1 = tf.nn.max_pool(conv1, [1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        conv2 = tf.nn.conv2d(max1, weights['wc2'], [1, 1, 1, 1], padding='SAME')\n",
    "        conv2 = tf.add(conv2, bias['bc2'])\n",
    "        conv2 = tf.nn.relu(conv2)\n",
    "        max2 = tf.nn.max_pool(conv2, [1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        conv3 = tf.nn.conv2d(max2, weights['wc3'], [1, 1, 1, 1], padding='SAME')\n",
    "        conv3 = tf.add(conv3, bias['bc3'])\n",
    "        conv3 = tf.nn.relu(conv3)\n",
    "        b, h, w, c = conv3.get_shape().as_list()\n",
    "        unrolled = tf.reshape(max2, [-1, h * w * c])\n",
    "        full1 = tf.add(tf.matmul(unrolled, weights['wf1']), bias['bf1'])\n",
    "        full1 = tf.nn.relu(full1)\n",
    "        full2 = tf.add(tf.matmul(full1, weights['wf2']), bias['bf2'])\n",
    "        full2 = tf.nn.relu(full2)\n",
    "        out = tf.add(tf.matmul(full2, weights['out']), bias['out'])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cifar_weights = {\n",
    "    'wc1' : tf.Variable(tf.truncated_normal([5, 5, 3, 96])),\n",
    "    'wc2' : tf.Variable(tf.truncated_normal([1, 1, 96, 96])),\n",
    "    'wc3' : tf.Variable(tf.truncated_normal([5, 5, 96, 196])),\n",
    "    'wc4' : tf.Variable(tf.truncated_normal([1, 1, 196, 196])),\n",
    "    'wc5' : tf.Variable(tf.truncated_normal([3, 3, 196, 192])),\n",
    "    'wc6' : tf.Variable(tf.truncated_normal([1, 1, 192, 64])),\n",
    "    'wc7' : tf.Variable(tf.truncated_normal([1, 1, 192, 10])),\n",
    "    'wc8' : tf.Variable(tf.truncated_normal([1, 1, 10, 3])),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cifar_bias = {\n",
    "    'bc1' : tf.Variable(tf.zeros([96])),\n",
    "    'bc2' : tf.Variable(tf.zeros([96])),\n",
    "    'bc3' : tf.Variable(tf.zeros([196])),\n",
    "    'bc4' : tf.Variable(tf.zeros([196])),\n",
    "    'bc5' : tf.Variable(tf.zeros([192])),\n",
    "    'bc6' : tf.Variable(tf.zeros([64])),\n",
    "    'bc7' : tf.Variable(tf.zeros([10])), \n",
    "    'bc8' : tf.Variable(tf.zeros([3])), \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv(image, weight_id, bais_id):\n",
    "    conv = tf.nn.conv2d(image, cifar_weights[weight_id], [1, 1, 1, 1], padding='SAME')\n",
    "    conv = tf.nn.bias_add(conv, cifar_bias[bais_id])\n",
    "    return tf.nn.relu(conv)\n",
    "\n",
    "def max_pool(image, k = 2, stride = 2):\n",
    "    return tf.nn.max_pool(image, [1, k, k, 1], strides=[1, stride, stride, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recreating the cifar conv net\n",
    "def conv_cifar(input_image):\n",
    "    conv1 = conv(input_image, 'wc1', 'bc1')\n",
    "#     conv2 = conv(conv1, 'wc2', 'bc2')\n",
    "    max1 = max_pool(conv1)#conv2\n",
    "    conv3 = conv(max1, 'wc3', 'bc3')\n",
    "#     conv4 = conv(conv3, 'wc4', 'bc4')\n",
    "    max2 = max_pool(conv3)#conv4\n",
    "    conv5 = conv(max2, 'wc5', 'bc5')\n",
    "    conv6 = conv(conv5, 'wc6', 'bc6')\n",
    "    b, h, w, c = conv6.get_shape().as_list()\n",
    "#     conv7 = conv(conv6, 'wc7', 'bc7')\n",
    "#     conv8 = conv(conv7, 'wc8', 'bc8')\n",
    "#     out = tf.nn.avg_pool(conv8, [1, 8, 8, 1], strides=[1, 1, 1, 1], padding='VALID')\n",
    "#     out = tf.reshape(out, [-1, 3])\n",
    "    unrolled = tf.reshape(conv6, [-1, h * w * c])\n",
    "    full1 = tf.add(tf.matmul(unrolled, weights['wf1']), bias['bf1'])\n",
    "    full1 = tf.nn.relu(full1)\n",
    "    full2 = tf.add(tf.matmul(full1, weights['wf2']), bias['bf2'])\n",
    "    full2 = tf.nn.relu(full2)\n",
    "    out = tf.add(tf.matmul(full2, weights['out']), bias['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_cifar(tf.random_normal([6, 32, 32, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Add_11:0' shape=(6, 3) dtype=float32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_net(tf.random_normal([6, 32, 32, 3])) #run excatly twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = conv_net(X)\n",
    "# pred = conv_cifar(X)\n",
    "output = tf.argmax(pred, axis = 1, name = 'final_output')\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred))\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "corrected_pred = tf.equal(tf.arg_max(pred, 1), tf.arg_max(y, 1))\n",
    "acc = tf.reduce_mean(tf.cast(corrected_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175, 3)\n",
      "Iter 0, Validation Acc 0.6857, Training loss 12297.1631\n",
      "Iter 10, Validation Acc 0.6571, Training loss 10976.6914\n",
      "Iter 20, Validation Acc 0.6400, Training loss 11640.8350\n",
      "Iter 30, Validation Acc 0.6629, Training loss 12292.6484\n",
      "Iter 40, Validation Acc 0.6857, Training loss 12202.7119\n",
      "Iter 50, Validation Acc 0.6800, Training loss 11365.2598\n",
      "Iter 60, Validation Acc 0.6686, Training loss 11117.3174\n",
      "Iter 70, Validation Acc 0.6800, Training loss 11264.8604\n",
      "Iter 80, Validation Acc 0.6629, Training loss 11387.2275\n",
      "Iter 90, Validation Acc 0.6800, Training loss 11246.0674\n",
      "Iter 100, Validation Acc 0.6800, Training loss 11762.5576\n",
      "Iter 110, Validation Acc 0.6686, Training loss 11403.9668\n",
      "Iter 120, Validation Acc 0.6686, Training loss 13523.2461\n",
      "Iter 130, Validation Acc 0.6457, Training loss 11733.2383\n",
      "Iter 140, Validation Acc 0.6743, Training loss 10857.7734\n",
      "Iter 150, Validation Acc 0.6914, Training loss 11296.2441\n",
      "Iter 160, Validation Acc 0.7029, Training loss 11203.2988\n",
      "Iter 170, Validation Acc 0.6571, Training loss 11336.7471\n",
      "Iter 180, Validation Acc 0.6286, Training loss 11754.3525\n",
      "Iter 190, Validation Acc 0.6229, Training loss 12122.1582\n",
      "Iter 200, Validation Acc 0.6571, Training loss 11171.1230\n",
      "Iter 210, Validation Acc 0.6743, Training loss 11772.2559\n",
      "Iter 220, Validation Acc 0.6629, Training loss 12114.4912\n",
      "Iter 230, Validation Acc 0.6857, Training loss 11353.4258\n",
      "Iter 240, Validation Acc 0.6743, Training loss 11827.8516\n",
      "Iter 250, Validation Acc 0.6286, Training loss 12943.9014\n",
      "Iter 260, Validation Acc 0.6514, Training loss 11816.7520\n",
      "Iter 270, Validation Acc 0.6571, Training loss 11488.4160\n",
      "Iter 280, Validation Acc 0.6629, Training loss 12197.0039\n",
      "Iter 290, Validation Acc 0.6629, Training loss 11458.9990\n",
      "Iter 300, Validation Acc 0.6457, Training loss 11545.1182\n",
      "Iter 310, Validation Acc 0.6743, Training loss 11006.4834\n",
      "Iter 320, Validation Acc 0.6343, Training loss 11493.3584\n",
      "Iter 330, Validation Acc 0.6629, Training loss 11172.1377\n",
      "Iter 340, Validation Acc 0.6857, Training loss 11018.9219\n",
      "Iter 350, Validation Acc 0.6743, Training loss 10933.1270\n",
      "Iter 360, Validation Acc 0.6686, Training loss 10936.4473\n",
      "Iter 370, Validation Acc 0.6743, Training loss 11583.1602\n",
      "Iter 380, Validation Acc 0.6743, Training loss 11253.4648\n",
      "Iter 390, Validation Acc 0.6400, Training loss 12403.3701\n",
      "Iter 400, Validation Acc 0.6686, Training loss 11121.3428\n",
      "Iter 410, Validation Acc 0.6400, Training loss 12314.0410\n",
      "Iter 420, Validation Acc 0.6629, Training loss 12005.3027\n",
      "Iter 430, Validation Acc 0.6800, Training loss 12802.9561\n",
      "Iter 440, Validation Acc 0.6686, Training loss 12018.2861\n",
      "Iter 450, Validation Acc 0.6629, Training loss 11471.6074\n",
      "Iter 460, Validation Acc 0.6800, Training loss 11621.2852\n",
      "Iter 470, Validation Acc 0.6629, Training loss 12065.8867\n",
      "Iter 480, Validation Acc 0.6800, Training loss 11414.7207\n",
      "Iter 490, Validation Acc 0.6686, Training loss 11622.7881\n",
      "Iter 500, Validation Acc 0.6514, Training loss 11650.3555\n",
      "Iter 510, Validation Acc 0.6857, Training loss 11422.4980\n",
      "Iter 520, Validation Acc 0.6571, Training loss 11740.8232\n",
      "Iter 530, Validation Acc 0.6743, Training loss 11960.9785\n",
      "Iter 540, Validation Acc 0.6800, Training loss 11943.4590\n",
      "Iter 550, Validation Acc 0.6686, Training loss 10931.5996\n",
      "Iter 560, Validation Acc 0.6629, Training loss 11057.3154\n",
      "Iter 570, Validation Acc 0.6286, Training loss 11851.4209\n",
      "Iter 580, Validation Acc 0.6629, Training loss 11905.5898\n",
      "Iter 590, Validation Acc 0.6571, Training loss 11490.3818\n",
      "Iter 600, Validation Acc 0.6743, Training loss 11171.9355\n",
      "Iter 610, Validation Acc 0.6743, Training loss 11649.4961\n",
      "Iter 620, Validation Acc 0.6571, Training loss 11274.1006\n",
      "Iter 630, Validation Acc 0.6629, Training loss 11498.8682\n",
      "Iter 640, Validation Acc 0.6629, Training loss 11935.2520\n",
      "Iter 650, Validation Acc 0.6514, Training loss 11658.4238\n",
      "Iter 660, Validation Acc 0.6571, Training loss 10688.4775\n",
      "Iter 670, Validation Acc 0.6400, Training loss 11961.4541\n",
      "Iter 680, Validation Acc 0.6743, Training loss 11496.5283\n",
      "Iter 690, Validation Acc 0.6571, Training loss 11407.1719\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Enqueue operation was cancelled\n",
      "\t [[Node: input_producer_1/input_producer/fraction_of_32_full/fraction_of_32_full_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_producer_1/input_producer/fraction_of_32_full/fraction_of_32_full, input_producer_1/input_producer/fraction_of_32_full/RandomShuffle)]]\n",
      "\n",
      "Caused by op 'input_producer_1/input_producer/fraction_of_32_full/fraction_of_32_full_EnqueueMany', defined at:\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/__main__.py\", line 3, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 474, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 887, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-11-4dc8008b9ebf>\", line 6, in <module>\n",
      "    shuffle=True)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py\", line 305, in slice_input_producer\n",
      "    shared_name=shared_name)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py\", line 262, in range_input_producer\n",
      "    shared_name, name, \"fraction_of_%d_full\" % capacity)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/input.py\", line 162, in input_producer\n",
      "    enq = q.enqueue_many([input_tensor])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/data_flow_ops.py\", line 367, in enqueue_many\n",
      "    self._queue_ref, vals, name=scope)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 1538, in _queue_enqueue_many_v2\n",
      "    name=name)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n",
      "    op_def=op_def)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2327, in create_op\n",
      "    original_op=self._default_original_op, op_def=op_def)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1226, in __init__\n",
      "    self._traceback = _extract_stack()\n",
      "\n",
      "CancelledError (see above for traceback): Enqueue operation was cancelled\n",
      "\t [[Node: input_producer_1/input_producer/fraction_of_32_full/fraction_of_32_full_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_producer_1/input_producer/fraction_of_32_full/fraction_of_32_full, input_producer_1/input_producer/fraction_of_32_full/RandomShuffle)]]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-9b2284ef5a68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mohe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplay\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mval_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mval_lab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    if isfile('models/new_model.ckpt.index'):\n",
    "        saver.restore(sess, 'models/new_model.ckpt')\n",
    "    val_img, val_lab = sess.run(vali_batch)\n",
    "    val_lab = ohe.transform(val_lab.reshape(-1, 1)).toarray()\n",
    "    print(val_lab.shape)\n",
    "    for i in range(training_iters):\n",
    "        image, label = sess.run(train_batch)\n",
    "        label = ohe.transform(label.reshape(-1, 1)).toarray()\n",
    "        temp, _ = sess.run([loss, train_op], feed_dict={X:image, y:label, keep_prob:drop})\n",
    "        if i % display == 0:\n",
    "            val_loss, accuracy = sess.run([loss, acc], feed_dict={X:val_img, y:val_lab, keep_prob:1.0})\n",
    "            print('Iter %s, Validation Acc %.4f, Training loss %.4f'%(i, accuracy, val_loss))  \n",
    "            save_path = saver.save(sess, \"models/new_model.ckpt\")\n",
    "    print('Saved and Optimized')\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freeze_graph('models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
