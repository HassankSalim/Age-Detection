{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.framework import dtypes\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.python.framework import graph_util\n",
    "from os.path import isfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_directory = 'data/'\n",
    "image_directory = 'data/Pre_train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='all', dtype=<class 'numpy.float64'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.fit(np.arange(3).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.transform([[0], [1], [2]]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = 32\n",
    "batch_size = 256\n",
    "num_channels = 3\n",
    "training_iters = 500\n",
    "display = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_label_files(csv_file):\n",
    "    file = open(data_directory+csv_file, 'r')\n",
    "    filepaths = []\n",
    "    labels = []\n",
    "    for i in file:\n",
    "        filename, label = i.split(',')\n",
    "        filepaths.append(image_directory+filename)\n",
    "        labels.append(int(label))\n",
    "    return filepaths, labels    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path, train_labels = read_label_files('train_set.csv')\n",
    "vali_path, vali_labels = read_label_files('vali_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vali_batch_size = len(vali_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path_tensor = ops.convert_to_tensor(train_path, dtype=dtypes.string)\n",
    "vali_path_tensor = ops.convert_to_tensor(vali_path, dtype=dtypes.string)\n",
    "train_labels_tensor = ops.convert_to_tensor(train_labels, dtype=dtypes.int32)\n",
    "vali_labels_tensor = ops.convert_to_tensor(vali_labels, dtype=dtypes.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input_queue = tf.train.slice_input_producer(\n",
    "                                    [train_path_tensor, train_labels_tensor],\n",
    "                                    shuffle=True)\n",
    "vali_input_queue = tf.train.slice_input_producer(\n",
    "                                    [vali_path_tensor, vali_labels_tensor],\n",
    "                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_content = tf.read_file(train_input_queue[0])\n",
    "train_image = tf.image.decode_jpeg(file_content, channels=num_channels)\n",
    "train_image /= 255\n",
    "train_label = train_input_queue[1]\n",
    "\n",
    "file_content = tf.read_file(vali_input_queue[0])\n",
    "vali_image = tf.image.decode_jpeg(file_content, channels=num_channels)\n",
    "vali_image /= 255\n",
    "vali_label = vali_input_queue[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_image.set_shape([size, size, num_channels])\n",
    "vali_image.set_shape([size, size, num_channels])\n",
    "\n",
    "train_batch = tf.train.batch(\n",
    "                            [train_image, train_label],\n",
    "                            batch_size= batch_size\n",
    "                            )\n",
    "vali_batch = tf.train.batch(\n",
    "                            [vali_image, vali_label],\n",
    "                            batch_size = vali_batch_size\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def freeze_graph(model_folder):\n",
    "\n",
    "    checkpoint = tf.train.get_checkpoint_state(model_folder)\n",
    "    input_checkpoint = checkpoint.model_checkpoint_path\n",
    "    model_name = 'basic_model'\n",
    "    absolute_model_folder = \"/\".join(input_checkpoint.split('/')[:-1])\n",
    "    output_graph = absolute_model_folder + \"/\" + model_name + \".pb\"\n",
    "\n",
    "    output_node_names = \"final_output\"\n",
    "\n",
    "    clear_devices = True\n",
    "\n",
    "    saver = tf.train.import_meta_graph(input_checkpoint + '.meta', clear_devices=clear_devices)\n",
    "\n",
    "    graph = tf.get_default_graph()\n",
    "    input_graph_def = graph.as_graph_def()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, input_checkpoint)\n",
    "\n",
    "        output_graph_def = graph_util.convert_variables_to_constants(\n",
    "            sess,\n",
    "            input_graph_def,\n",
    "            output_node_names.split(\",\")\n",
    "        )\n",
    "\n",
    "        with tf.gfile.GFile(output_graph, \"wb\") as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "        print(\"%d ops in the final graph.\" % len(output_graph_def.node))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     coord = tf.train.Coordinator()\n",
    "#     threads = tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "#     for i in range(1):\n",
    "#         test = sess.run(train_batch)\n",
    "#     coord.request_stop()\n",
    "#     coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# image, label = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(image.shape)\n",
    "# print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape = [None, size, size, 3])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "        'wc1':tf.Variable(tf.random_normal([5, 5, 3, 32])),\n",
    "        'wc2':tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "        'wc3':tf.Variable(tf.random_normal([3, 3, 64, 64])),\n",
    "        'wf1':tf.Variable(tf.random_normal([8 * 8 * 64, 1024])),\n",
    "        'out':tf.Variable(tf.random_normal([1024, 3]))\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bias = {\n",
    "        'bc1' : tf.Variable(tf.random_normal([32])),\n",
    "        'bc2' : tf.Variable(tf.random_normal([64])),\n",
    "        'bc3' : tf.Variable(tf.random_normal([64])),\n",
    "        'bf1' : tf.Variable(tf.random_normal([1024])),\n",
    "        'out':tf.Variable(tf.random_normal([3]))\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_net(input_image):\n",
    "        conv1 = tf.nn.conv2d(input_image, weights['wc1'], [1, 1, 1, 1], padding='SAME')\n",
    "        conv1 = tf.add(conv1, bias['bc1'])\n",
    "        max1 = tf.nn.max_pool(conv1, [1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        conv2 = tf.nn.conv2d(max1, weights['wc2'], [1, 1, 1, 1], padding='SAME')\n",
    "        conv2 = tf.add(conv2, bias['bc2'])\n",
    "        conv3 = tf.nn.conv2d(conv2, weights['wc3'], [1, 1, 1, 1], padding='SAME')\n",
    "        conv3 = tf.add(conv3, bias['bc3'])\n",
    "        max2 = tf.nn.max_pool(conv3, [1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        b, h, w, c = max2.get_shape().as_list()\n",
    "        unrolled = tf.reshape(max2, [-1, h * w * c])\n",
    "        full1 = tf.add(tf.matmul(unrolled, weights['wf1']), bias['bf1'])\n",
    "        out = tf.add(tf.matmul(full1, weights['out']), bias['out'])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Add_4:0' shape=(6, 3) dtype=float32>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_net(tf.random_normal([6, 32, 32, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = conv_net(X)\n",
    "output = tf.argmax(pred, axis = 1, name = 'final_output')\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred))\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "corrected_pred = tf.equal(tf.arg_max(pred, 1), tf.arg_max(y, 1))\n",
    "acc = tf.reduce_mean(tf.cast(corrected_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 3)\n",
      "Iter 0, Validation Acc 0.6000, Training loss 124666.6016\n",
      "Iter 10, Validation Acc 0.6300, Training loss 119675.0078\n",
      "Iter 20, Validation Acc 0.6600, Training loss 125022.3828\n",
      "Iter 30, Validation Acc 0.6700, Training loss 120318.7188\n",
      "Iter 40, Validation Acc 0.5200, Training loss 177471.4375\n",
      "Iter 50, Validation Acc 0.5800, Training loss 139528.0000\n",
      "Iter 60, Validation Acc 0.5150, Training loss 192441.0469\n",
      "Iter 70, Validation Acc 0.4900, Training loss 158532.8750\n",
      "Iter 80, Validation Acc 0.6150, Training loss 143947.7031\n",
      "Iter 90, Validation Acc 0.6050, Training loss 146866.7969\n",
      "Iter 100, Validation Acc 0.5800, Training loss 135310.7656\n",
      "Iter 110, Validation Acc 0.6500, Training loss 115331.1016\n",
      "Iter 120, Validation Acc 0.6150, Training loss 113031.8203\n",
      "Iter 130, Validation Acc 0.6650, Training loss 129239.4766\n",
      "Iter 140, Validation Acc 0.5750, Training loss 135996.5938\n",
      "Iter 150, Validation Acc 0.6150, Training loss 127863.8594\n",
      "Iter 160, Validation Acc 0.4950, Training loss 173641.1562\n",
      "Iter 170, Validation Acc 0.6100, Training loss 115703.8828\n",
      "Iter 180, Validation Acc 0.6100, Training loss 123706.2578\n",
      "Iter 190, Validation Acc 0.6800, Training loss 107145.2422\n",
      "Iter 200, Validation Acc 0.6300, Training loss 116853.2969\n",
      "Iter 210, Validation Acc 0.6700, Training loss 112592.7422\n",
      "Iter 220, Validation Acc 0.5800, Training loss 123777.9766\n",
      "Iter 230, Validation Acc 0.6600, Training loss 107990.6328\n",
      "Iter 240, Validation Acc 0.6350, Training loss 118335.7109\n",
      "Iter 250, Validation Acc 0.6950, Training loss 110896.2500\n",
      "Iter 260, Validation Acc 0.5900, Training loss 117345.2812\n",
      "Iter 270, Validation Acc 0.5950, Training loss 124915.6875\n",
      "Iter 280, Validation Acc 0.5750, Training loss 118510.5078\n",
      "Iter 290, Validation Acc 0.6600, Training loss 110885.4062\n",
      "Iter 300, Validation Acc 0.6500, Training loss 124884.5781\n",
      "Iter 310, Validation Acc 0.6500, Training loss 120351.6719\n",
      "Iter 320, Validation Acc 0.6100, Training loss 121189.6172\n",
      "Iter 330, Validation Acc 0.5400, Training loss 144518.0000\n",
      "Iter 340, Validation Acc 0.6250, Training loss 140746.6875\n",
      "Iter 350, Validation Acc 0.6100, Training loss 129986.2578\n",
      "Iter 360, Validation Acc 0.6200, Training loss 104900.9219\n",
      "Iter 370, Validation Acc 0.6050, Training loss 123818.5391\n",
      "Iter 380, Validation Acc 0.5700, Training loss 118761.1875\n",
      "Iter 390, Validation Acc 0.6950, Training loss 132461.7188\n",
      "Iter 400, Validation Acc 0.6350, Training loss 106603.7969\n",
      "Iter 410, Validation Acc 0.6550, Training loss 124235.2812\n",
      "Iter 420, Validation Acc 0.6300, Training loss 114015.9609\n",
      "Iter 430, Validation Acc 0.6650, Training loss 112031.2578\n",
      "Iter 440, Validation Acc 0.6300, Training loss 106943.7031\n",
      "Iter 450, Validation Acc 0.6300, Training loss 117530.3125\n",
      "Iter 460, Validation Acc 0.6150, Training loss 125334.9219\n",
      "Iter 470, Validation Acc 0.5750, Training loss 111231.2578\n",
      "Iter 480, Validation Acc 0.6350, Training loss 119188.5000\n",
      "Iter 490, Validation Acc 0.6600, Training loss 110494.1562\n",
      "Saved and Optimized\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    if isfile('models/model.ckpt.index'):\n",
    "        saver.restore(sess, 'models/model.ckpt')\n",
    "    val_img, val_lab = sess.run(vali_batch)\n",
    "    val_lab = ohe.transform(val_lab.reshape(-1, 1)).toarray()\n",
    "    print(val_lab.shape)\n",
    "    \n",
    "    for i in range(training_iters):\n",
    "        image, label = sess.run(train_batch)\n",
    "        label = ohe.transform(label.reshape(-1, 1)).toarray()\n",
    "        temp, _ = sess.run([loss, train_op], feed_dict={X:image, y:label})\n",
    "        if i % display == 0:\n",
    "            val_loss, accuracy = sess.run([loss, acc], feed_dict={X:val_img, y:val_lab})\n",
    "            save_path = saver.save(sess, \"models/model.ckpt\")\n",
    "            print('Iter %s, Validation Acc %.4f, Training loss %.4f'%(i, accuracy, val_loss))\n",
    "    print('Saved and Optimized')\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 10 variables.\n",
      "Converted 10 variables to const ops.\n",
      "37 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "freeze_graph('models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
