{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.framework import dtypes\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.python.framework import graph_util\n",
    "from os.path import isfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_directory = 'data/'\n",
    "image_directory = 'data/Pre_train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='all', dtype=<class 'numpy.float64'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.fit(np.arange(3).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.transform([[0], [1], [2]]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = 32\n",
    "batch_size = 256\n",
    "num_channels = 3\n",
    "training_iters = 500\n",
    "display = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_label_files(csv_file):\n",
    "    file = open(data_directory+csv_file, 'r')\n",
    "    filepaths = []\n",
    "    labels = []\n",
    "    for i in file:\n",
    "        filename, label = i.split(',')\n",
    "        filepaths.append(image_directory+filename)\n",
    "        labels.append(int(label))\n",
    "    return filepaths, labels    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path, train_labels = read_label_files('train_set.csv')\n",
    "vali_path, vali_labels = read_label_files('vali_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vali_batch_size = len(vali_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path_tensor = ops.convert_to_tensor(train_path, dtype=dtypes.string)\n",
    "vali_path_tensor = ops.convert_to_tensor(vali_path, dtype=dtypes.string)\n",
    "train_labels_tensor = ops.convert_to_tensor(train_labels, dtype=dtypes.int32)\n",
    "vali_labels_tensor = ops.convert_to_tensor(vali_labels, dtype=dtypes.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input_queue = tf.train.slice_input_producer(\n",
    "                                    [train_path_tensor, train_labels_tensor],\n",
    "                                    shuffle=True)\n",
    "vali_input_queue = tf.train.slice_input_producer(\n",
    "                                    [vali_path_tensor, vali_labels_tensor],\n",
    "                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_content = tf.read_file(train_input_queue[0])\n",
    "train_image = tf.image.decode_jpeg(file_content, channels=num_channels)\n",
    "train_image /= 255\n",
    "train_label = train_input_queue[1]\n",
    "\n",
    "file_content = tf.read_file(vali_input_queue[0])\n",
    "vali_image = tf.image.decode_jpeg(file_content, channels=num_channels)\n",
    "vali_image /= 255\n",
    "vali_label = vali_input_queue[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_image.set_shape([size, size, num_channels])\n",
    "vali_image.set_shape([size, size, num_channels])\n",
    "\n",
    "train_batch = tf.train.batch(\n",
    "                            [train_image, train_label],\n",
    "                            batch_size= batch_size\n",
    "                            )\n",
    "vali_batch = tf.train.batch(\n",
    "                            [vali_image, vali_label],\n",
    "                            batch_size = vali_batch_size\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def freeze_graph(model_folder):\n",
    "\n",
    "    checkpoint = tf.train.get_checkpoint_state(model_folder)\n",
    "    input_checkpoint = checkpoint.model_checkpoint_path\n",
    "    model_name = 'basic_model'\n",
    "    absolute_model_folder = \"/\".join(input_checkpoint.split('/')[:-1])\n",
    "    output_graph = absolute_model_folder + \"/\" + model_name + \".pb\"\n",
    "\n",
    "    output_node_names = \"final_output\"\n",
    "\n",
    "    clear_devices = True\n",
    "\n",
    "    saver = tf.train.import_meta_graph(input_checkpoint + '.meta', clear_devices=clear_devices)\n",
    "\n",
    "    graph = tf.get_default_graph()\n",
    "    input_graph_def = graph.as_graph_def()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, input_checkpoint)\n",
    "\n",
    "        output_graph_def = graph_util.convert_variables_to_constants(\n",
    "            sess,\n",
    "            input_graph_def,\n",
    "            output_node_names.split(\",\")\n",
    "        )\n",
    "\n",
    "        with tf.gfile.GFile(output_graph, \"wb\") as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "        print(\"%d ops in the final graph.\" % len(output_graph_def.node))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     coord = tf.train.Coordinator()\n",
    "#     threads = tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "#     for i in range(1):\n",
    "#         test = sess.run(train_batch)\n",
    "#     coord.request_stop()\n",
    "#     coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# image, label = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(image.shape)\n",
    "# print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape = [None, size, size, 3])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "        'wc1':tf.Variable(tf.random_normal([5, 5, 3, 32])),\n",
    "        'wc2':tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "        'wc3':tf.Variable(tf.random_normal([3, 3, 64, 64])),\n",
    "        'wf1':tf.Variable(tf.random_normal([8 * 8 * 64, 1024])),\n",
    "        'out':tf.Variable(tf.random_normal([1024, 3]))\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bias = {\n",
    "        'bc1' : tf.Variable(tf.random_normal([32])),\n",
    "        'bc2' : tf.Variable(tf.random_normal([64])),\n",
    "        'bc3' : tf.Variable(tf.random_normal([64])),\n",
    "        'bf1' : tf.Variable(tf.random_normal([1024])),\n",
    "        'out':tf.Variable(tf.random_normal([3]))\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_net(input_image):\n",
    "        conv1 = tf.nn.conv2d(input_image, weights['wc1'], [1, 1, 1, 1], padding='SAME')\n",
    "        conv1 = tf.add(conv1, bias['bc1'])\n",
    "        max1 = tf.nn.max_pool(conv1, [1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        conv2 = tf.nn.conv2d(max1, weights['wc2'], [1, 1, 1, 1], padding='SAME')\n",
    "        conv2 = tf.add(conv2, bias['bc2'])\n",
    "        conv3 = tf.nn.conv2d(conv2, weights['wc3'], [1, 1, 1, 1], padding='SAME')\n",
    "        conv3 = tf.add(conv3, bias['bc3'])\n",
    "        max2 = tf.nn.max_pool(conv3, [1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        b, h, w, c = max2.get_shape().as_list()\n",
    "        unrolled = tf.reshape(max2, [-1, h * w * c])\n",
    "        full1 = tf.add(tf.matmul(unrolled, weights['wf1']), bias['bf1'])\n",
    "        out = tf.add(tf.matmul(full1, weights['out']), bias['out'])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Add_4:0' shape=(6, 3) dtype=float32>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_net(tf.random_normal([6, 32, 32, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = conv_net(X)\n",
    "output = tf.argmax(pred, axis = 1, name = 'final_output')\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred))\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "corrected_pred = tf.equal(tf.arg_max(pred, 1), tf.arg_max(y, 1))\n",
    "acc = tf.reduce_mean(tf.cast(corrected_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 3)\n",
      "Iter 0, Validation Acc 0.6500, Training loss 86488.1406\n",
      "Iter 10, Validation Acc 0.7100, Training loss 81676.8125\n",
      "Iter 20, Validation Acc 0.6650, Training loss 86307.2422\n",
      "Iter 30, Validation Acc 0.6350, Training loss 91004.9062\n",
      "Iter 40, Validation Acc 0.6300, Training loss 87056.9766\n",
      "Iter 50, Validation Acc 0.6700, Training loss 87728.7969\n",
      "Iter 60, Validation Acc 0.6450, Training loss 84402.2891\n",
      "Iter 70, Validation Acc 0.6550, Training loss 95697.2422\n",
      "Iter 80, Validation Acc 0.6600, Training loss 81169.6875\n",
      "Iter 90, Validation Acc 0.5950, Training loss 104298.0312\n",
      "Iter 100, Validation Acc 0.5900, Training loss 94830.7188\n",
      "Iter 110, Validation Acc 0.6300, Training loss 100653.4375\n",
      "Iter 120, Validation Acc 0.6200, Training loss 91069.7188\n",
      "Iter 130, Validation Acc 0.6600, Training loss 85464.5703\n",
      "Iter 140, Validation Acc 0.6400, Training loss 93327.0703\n",
      "Iter 150, Validation Acc 0.6550, Training loss 86354.1172\n",
      "Iter 160, Validation Acc 0.6700, Training loss 81847.5312\n",
      "Iter 170, Validation Acc 0.6100, Training loss 95045.3281\n",
      "Iter 180, Validation Acc 0.6000, Training loss 92376.4062\n",
      "Iter 190, Validation Acc 0.6300, Training loss 83514.3594\n",
      "Iter 200, Validation Acc 0.6350, Training loss 88539.6562\n",
      "Iter 210, Validation Acc 0.6700, Training loss 83695.4062\n",
      "Iter 220, Validation Acc 0.6650, Training loss 88665.7500\n",
      "Iter 230, Validation Acc 0.6450, Training loss 79717.9062\n",
      "Iter 240, Validation Acc 0.6250, Training loss 95533.7969\n",
      "Iter 250, Validation Acc 0.6650, Training loss 84444.0625\n",
      "Iter 260, Validation Acc 0.6200, Training loss 94700.1406\n",
      "Iter 270, Validation Acc 0.5550, Training loss 116990.2188\n",
      "Iter 280, Validation Acc 0.6450, Training loss 88773.4766\n",
      "Iter 290, Validation Acc 0.6700, Training loss 102139.8203\n",
      "Iter 300, Validation Acc 0.6350, Training loss 97221.5625\n",
      "Iter 310, Validation Acc 0.6600, Training loss 89561.3594\n",
      "Iter 320, Validation Acc 0.6400, Training loss 95441.9062\n",
      "Iter 330, Validation Acc 0.6100, Training loss 96263.6406\n",
      "Iter 340, Validation Acc 0.6500, Training loss 86047.2578\n",
      "Iter 350, Validation Acc 0.6600, Training loss 86798.1875\n",
      "Iter 360, Validation Acc 0.6500, Training loss 80853.1016\n",
      "Iter 370, Validation Acc 0.6500, Training loss 97141.4219\n",
      "Iter 380, Validation Acc 0.6650, Training loss 81976.2109\n",
      "Iter 390, Validation Acc 0.6400, Training loss 83315.1094\n",
      "Iter 400, Validation Acc 0.6100, Training loss 89303.0625\n",
      "Iter 410, Validation Acc 0.6150, Training loss 93134.1875\n",
      "Iter 420, Validation Acc 0.6550, Training loss 93763.6172\n",
      "Iter 430, Validation Acc 0.6600, Training loss 80564.4219\n",
      "Iter 440, Validation Acc 0.5950, Training loss 86646.0625\n",
      "Iter 450, Validation Acc 0.5950, Training loss 93702.2578\n",
      "Iter 460, Validation Acc 0.6100, Training loss 95498.7422\n",
      "Iter 470, Validation Acc 0.6350, Training loss 81602.4609\n",
      "Iter 480, Validation Acc 0.5850, Training loss 102200.6484\n",
      "Iter 490, Validation Acc 0.6550, Training loss 78595.8594\n",
      "Saved and Optimized\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    if isfile('models/model.ckpt.index'):\n",
    "        saver.restore(sess, 'models/model.ckpt')\n",
    "    val_img, val_lab = sess.run(vali_batch)\n",
    "    val_lab = ohe.transform(val_lab.reshape(-1, 1)).toarray()\n",
    "    print(val_lab.shape)\n",
    "    \n",
    "    for i in range(training_iters):\n",
    "        image, label = sess.run(train_batch)\n",
    "        label = ohe.transform(label.reshape(-1, 1)).toarray()\n",
    "        temp, _ = sess.run([loss, train_op], feed_dict={X:image, y:label})\n",
    "        if i % display == 0:\n",
    "            val_loss, accuracy = sess.run([loss, acc], feed_dict={X:val_img, y:val_lab})\n",
    "            save_path = saver.save(sess, \"models/model.ckpt\")\n",
    "            print('Iter %s, Validation Acc %.4f, Training loss %.4f'%(i, accuracy, val_loss))\n",
    "    print('Saved and Optimized')\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 10 variables.\n",
      "Converted 10 variables to const ops.\n",
      "37 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "freeze_graph('models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
